{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637620a3",
   "metadata": {},
   "source": [
    "### Lab 3\n",
    "This lab activity has 3 parts. Use the provided information below to answer the questions. \n",
    "\n",
    "- Part 1: Mathematically provide the formulation for performing a Full-pass for the first mini-batch of data. \n",
    "- Part 2: Provide the mathematical formulation and pseudo-computation for the weight changes at each layer of the model during backpropagation and indicate the notations for the updated weights. \n",
    "- Part 3: Assume you have completed 1 epoch of training. How do you compute the error of your model after completing 1 epoch on training and testing data (separately)? Provide a pseudocode to describe your algorithm for reporting the training and testing error after each epoch to investigate when the model converges (after how many epochs). \n",
    "\n",
    "---\n",
    "\n",
    "![Generated Dataset](img/lab3.jpg)\n",
    "![Generated Dataset](img/lab3-1.jpg)\n",
    "![Generated Dataset](img/lab3-2.jpg)\n",
    "![Generated Dataset](img/lab3-3.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bd246b",
   "metadata": {},
   "source": [
    "### Part 1: Mathematically provide the formulation for performing a Full-pass for the first mini-batch of data. \n",
    "---\n",
    "First, we make calculations: input layer → first hidden layer (h₁) with neurons N₁ and N₂:\n",
    "\n",
    "- net_h₁₁ = w₁₁x₁ + w₁₂x₂ + w₁₀  (for N₁)\n",
    "- net_h₁₂ = w₂₁x₁ + w₂₂x₂ + w₂₀  (for N₂)\n",
    "\n",
    "- h₁₁ = σ(net_h₁₁)\n",
    "- h₁₂ = σ(net_h₁₂)\n",
    "\n",
    "We'll continue to the next layer: first hidden layer → second hidden layer (h₂) with neurons N₃ and N₄:\n",
    "\n",
    "- net_h₂₁ = w₃₁h₁₁ + w₃₂h₁₂ + w₃₀  (for N₃)\n",
    "- net_h₂₂ = w₄₁h₁₁ + w₄₂h₁₂ + w₄₀  (for N₄)\n",
    "\n",
    "- h₂₁ = σ(net_h₂₁)\n",
    "- h₂₂ = σ(net_h₂₂)\n",
    "\n",
    "We'll continue to the output layer: second hidden layer → output layer with output neurons N₅, N₆, N₇ (l₀, l₁, l₂):\n",
    "\n",
    "- net_o₀ = w₅₁h₂₁ + w₅₂h₂₂ + w₅₀  (for N₅/l₀)\n",
    "- net_o₁ = w₆₁h₂₁ + w₆₂h₂₂ + w₆₀  (for N₆/l₁)\n",
    "- net_o₂ = w₇₁h₂₁ + w₇₂h₂₂ + w₇₀  (for N₇/l₂)\n",
    "\n",
    "- o₀ = σ(net_o₀)\n",
    "- o₁ = σ(net_o₁)\n",
    "- o₂ = σ(net_o₂)\n",
    "\n",
    "Loss Computation: SSEₙ = ½[(yₙ - o₀)² + (yₙ - o₁)² + (yₙ - o₂)²]\n",
    "\n",
    "- yₙ: true label for the nth data point\n",
    "- o₀, o₁, o₂: predicted outputs for the three classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb31a5a",
   "metadata": {},
   "source": [
    "### Part 2: Provide the mathematical formulation and pseudo-computation for the weight changes at each layer of the model during backpropagation and indicate the notations for the updated weights.\n",
    "---\n",
    "\n",
    "First, we calculate error from output layer back to input layer.\n",
    "Output layer (N₅, N₆, N₇) - for each output neuron k, δₖ = oₖ(1 - oₖ)(y - oₖ) where:\n",
    "- oₖ is the output of neuron k\n",
    "- (1 - oₖ) is derivative of sigmoid\n",
    "- (y - oₖ) is the error term\n",
    "\n",
    "To update weights from h₂ to output - for weights connecting h₂ to output neurons, Δwₕ₂ₒ = η × δₖ × h₂ᵢ where:\n",
    "- η is learning rate\n",
    "- δₖ is error from output neuron\n",
    "- h₂ᵢ is output from second hidden layer neuron i\n",
    "\n",
    "Next, we'll calculate error for the second hidden layer (N₃, N₄). For each h₂ neuron i, δₕ₂ᵢ = h₂ᵢ(1 - h₂ᵢ)Σₖ(δₖwₖᵢ) where:\n",
    "- h₂ᵢ(1 - h₂ᵢ) is sigmoid derivative\n",
    "- Σₖ(δₖwₖᵢ) sums errors from all output neurons\n",
    "\n",
    "To udpate weights from h₁ to h₂ (for weights connecting h₁ to h₂) Δwₕ₁ₕ₂ = η × δₕ₂ᵢ × h₁ where:\n",
    "- δₕ₂ᵢ is error from h₂ neuron\n",
    "- h₁ⱼ is output from first hidden layer\n",
    "\n",
    "Finally, we'll calculate error for the first hidden layer (N₁, N₂). For each h₁ neuron j, δₕ₁ⱼ = h₁ⱼ(1 - h₁ⱼ)Σᵢ(δₕ₂ᵢwᵢⱼ).\n",
    "\n",
    "To update weights from Input to h₁ (weights connecting input to h₁) Δwᵢₕ₁ = η × δₕ₁ⱼ × xᵢ where:\n",
    "- xᵢ is the input value\n",
    "\n",
    "Final updated weights are: w_new = w_old + Δw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbef7daa",
   "metadata": {},
   "source": [
    "### Part 3: Assume you have completed 1 epoch of training. How do you compute the error of your model after completing 1 epoch on training and testing data (separately)?\n",
    "\n",
    "Provide a pseudocode to describe your algorithm for reporting the training and testing error after each epoch to investigate when the model converges (after how many epochs). \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "796b5515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model_error(data, model, mode='train'):\n",
    "    total_sse = 0\n",
    "    for batch in data:\n",
    "        # get model predictions for this batch and store in predictions\n",
    "        # add SSE for this batch and store in total_sse\n",
    "    return total_sse / length(data) # average error across all data\n",
    "\n",
    "def train_with_monitoring():\n",
    "    epoch = 0\n",
    "    prev_train_error = INFINITY             # initial previous error is set to infinity\n",
    "    patience = 5                            # wait 5 epochs before stopping if no improvement\n",
    "    no_improvement = 0                      # use this to count epochs without improvement\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        train_one_epoch(model, train_data)\n",
    "        \n",
    "        # compute train and test errors\n",
    "        train_error = compute_model_error(train_data, model, 'train')\n",
    "        test_error = compute_model_error(test_data, model, 'test')\n",
    "                \n",
    "        # checking for convergence (if training error is improving)\n",
    "        # if error got worse or stayed same\n",
    "        if train_error >= prev_train_error: \n",
    "            no_improvement += 1\n",
    "        # if error improved\n",
    "        else:\n",
    "            no_improvement = 0\n",
    "            \n",
    "        if no_improvement >= patience: # DO: PRINT MODEL CONVERGED AFTER __ EPOCHS \n",
    "            \n",
    "        prev_train_error = train_error # saving current error for next comparison\n",
    "        epoch += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
